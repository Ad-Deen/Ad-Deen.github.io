<!DOCTYPE HTML>
<!--
	Solid State by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Project : AUTOMAMA</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Page Wrapper -->
			<div id="page-wrapper">

				<!-- Header -->
					<header id="header">
						<h1><a href="index.html">Project : AUTOMAMA</a></h1>
						<nav>
							<a href="#menu">Menu</a>
						</nav>
					</header>

				<!-- Menu -->
					<nav id="menu">
						<div class="inner">
							<h2>Menu</h2>
							<ul class="links">
								<li><a href="index.html">Home</a></li>
								<li><a href="#wrapper">Projects</a></li>
								<li><a href="#four">Minor Projects</a></li>
								<li><a href="#footer">Contact</a></li>
								<li><a href="elements.html">elements</a></li>
							</ul>
							<a href="#" class="close">Close</a>
						</div>
					</nav>

				<!-- Wrapper -->
					<section id="wrapper">
						<header>
							<div class="inner">
								<h2>Autonoumous ground vehicle system </h2>
								<p>Campus TAXI - book online - give location - travel seamlessly - Battery SOC update from cloud</p>
							</div>
						</header>

						<!-- Content -->
							<div class="wrapper">
								<div class="inner">

									<h3 class="major">Technical Highlights</h3>
									<!-- Technical Highlights with side-by-side layout -->
										<div class="tech-highlights">

											<img src="images/Automama_nav.png" alt="Ad-Deen Mahbub" class="highlight-img" style="width: 50%;" />


											<p>
												Automama is our in-house Autonomous Ground Vehicle (AGV) project, designed to transform 
												a custom-built electric vehicle (EV) into a fully programmable robotic platform. 
												The EV chassis was enhanced with sensor feedback systems for <strong>braking, steering, 
												and acceleration</strong>, enabling complete drive-by-wire control.
											</p>

											<h3>Perception Pipeline</h3>
											<p>
												We integrated a <strong>stereo vision system</strong> using an IMX219 stereo camera pair. 
												Frames from the left camera were first processed through a 
												<strong>YOLOv8n-Segmentation model</strong> to segment roads and obstacles. 
												The segmentation masks guided <strong>stereo depth estimation</strong>, 
												allowing us to obtain precise depth information for both drivable areas and obstacles.
											</p>

											<h3>Mapping & Navigation</h3>
											<p>
												Using the depth maps, we constructed a <strong>2D occupancy grid</strong> of the road. 
												A custom local planner was developed to detect and follow the <strong>largest navigable gap</strong> 
												in real time, ensuring safe short-term path planning. This approach allows Automama to 
												react dynamically to changing environments.
											</p>

											<h3>Future Goals</h3>
											<p>
												Our long-term vision is to map the entire <strong>university campus</strong> and build 
												a global planner on top of the local navigation system. By integrating 
												<strong>visual odometry</strong> for localization, Automama will eventually 
												achieve seamless autonomous navigation across large-scale outdoor environments.
											</p>
										</div>

									<h3 class="major">snapshots of the progress</h3>
									<p>
										We have a step by step documentation of our project in the following sections. 
										Feel free to dive deep into our documentation in the github links however you 
										like !
									</p>

									<section class="features">
										<article>
											<a href="https://github.com/Ad-Deen/AGV-Project-Autonomous-Racing-F1-10th-AutoDrive-Simulator.git" class="image">
												<video src="images/PPO RL application in simulations.webm"" autoplay loop muted playsinline></video>
											</a>
											<h3 class="major">RL_Race: Custom PPO Training Architecture for Autonomous Racing</h3>
												<p>
													This project implements a fully custom Proximal Policy Optimization (PPO) training pipeline for autonomous racing in a ROS 2 and Ignition Gazebo Fortress environment. 
													The system uses end-to-end neural networks for both actor and critic models, without relying on pre-built RL libraries such as Gymnasium or Stable Baselines. 
													Continuous visual and LIDAR-based state representations allow the agent to learn optimal racing strategies, while integrated SLAM enables automatic mapping of the race track for safe and efficient navigation.
												</p>
											<a href="https://github.com/Ad-Deen/AGV-Project-Autonomous-Racing-F1-10th-AutoDrive-Simulator.git" class="special">Learn more</a>
										</article>
										<article>
											<a href="https://github.com/Ad-Deen/AGV-Custom-PPO-Training-Architecture-ROS2-Ign-Gazebo-Fortress.git" class="image">
												<video src="images/2D SLAM+Nav.mp4" autoplay loop muted playsinline></video>
											</a>
											<h3 class="major">AutoDrive DevKit: 2D SLAM & Optimal Path Planning for Racing</h3>
												<p>
													AutoDrive DevKit provides a complete framework for autonomous racing in a simulator environment. 
													It features 2D SLAM for mapping race tracks into occupancy grids, advanced path planning with A* and smoothing techniques, 
													and trajectory optimization for high-speed lap completion. The modular ROS 2 and Python-based system allows easy integration 
													with the AutoDrive Simulator, enabling safe and repeatable testing of autonomous racing strategies.
												</p>
											<a href="https://github.com/Ad-Deen/AGV-Custom-PPO-Training-Architecture-ROS2-Ign-Gazebo-Fortress.git" class="special">Learn more</a>
										</article>

										<article>
											<a href="https://github.com/Ad-Deen/AGV-Project-Automama-Simulation-Stack.git" class="image">
												<video src="images/automama_sim_compressed.webm" autoplay loop muted playsinline></video>
											</a>
											<h3 class="major"> A : Digital Twin of our Campus world in Gazebo</h3>
											<p>
												To enable safe, repeatable, and low-cost testing of the autonomous system, we 
												developed a custom Gazebo simulation environment that replicates our university 
												campus. This simulated world is used to test and validate Automama’s full 
												autonomous stack, including point-to-point navigation, control, and perception 
												modules.
											</p>
											<a href="https://github.com/Ad-Deen/AGV-Project-Automama-Simulation-Stack.git" class="special">Learn more</a>
										</article>
										<article>
											<a href="https://github.com/Ad-Deen/AGV-Project-Automama-Mechanical-Stack.git" class="image"><img src="images/mechanical stack.gif" alt="" /></a>
											<h3 class="major"> B : Mechanical Stack</h3>
											<p>
												Building the electrical control stack on top of proper mechanical stack was a big
												milestone in our initial work. We customized the control algorithm to throttle and
												steer seamlessly.
											</p>
											<a href="https://github.com/Ad-Deen/AGV-Project-Automama-Mechanical-Stack.git" class="special">Learn more</a>
										</article>
										<article>
											<a href="#" class="image"><img src="images/pic05.jpg" alt="" /></a>
											<h3 class="major"> C : Electrical Stack</h3>
											<p>
												In this documentation we detail the design and implementation of the electrical control
												stack for our Autonomous Ground Vehicle (AGV) project, Automama. The electrical stack consists
												of three main components: the sensor suite, the embedded control system, and the
												actuation interface. Together, these components enable precise drive-by-wire control of the 
												vehicle. We have future plans on adding renewable charging station and autonomous
												charging station system for the vehicle.
											</p>
											<a href="#" class="special">Learn more</a>
										</article>
										<article>
											<a href="https://github.com/Ad-Deen/AGV-Project_Automama-Software_stack/tree/main/automama/automama/perception" class="image">
												<video src="images/stereo vision working demo_compressed.mp4" autoplay loop muted playsinline></video>
											</a>
											<h3 class="major"> D : Perception Stack</h3>
											<p>
												Our AGV’s perception stack combines stereo vision and deep learning to interpret the 
												driving environment. A YOLOv8n-Seg model processes the left camera feed to identify 
												road regions and obstacles, while stereo depth estimation generates distance 
												information for these segmented areas. The depth data is projected into a 2D 
												occupancy grid, enabling the vehicle to detect free space and plan paths by following
												 the largest gap. This local perception system is integrated with visual odometry to 
												 support global mapping and navigation across the campus.
											</p>
											<a href="https://github.com/Ad-Deen/AGV-Project_Automama-Software_stack/tree/main/automama/automama/perception" class="special">Learn more</a>
										</article>
										<article>
											<a href="https://github.com/Ad-Deen/AGV-Project_Automama-Software_stack.git" class="image">
												<video src="images/auto_run_compressed.mp4" autoplay loop muted playsinline></video>
											</a>
											<h3 class="major"> E : Navigation Stack</h3>
											<p>
												Our navigation stack is designed for real-time decision-making with GPU-accelerated 
												processing. Using DMA and zero-copy memory, sensor data is efficiently streamed to 
												the GPU for parallel computation. A potential fields method guides trajectory 
												generation by balancing attraction toward the goal and repulsion from obstacles, 
												ensuring smooth and collision-free paths. On top of this, we apply vehicle kinematic 
												and dynamic constraints so that the planned trajectory remains feasible for the 
												AGV’s steering, braking, and acceleration limits.
											</p>
											<a href="https://github.com/Ad-Deen/AGV-Project_Automama-Software_stack.git" class="special">Learn more</a>
										</article>
										<article>
											<a href="#" class="image"><img src="images/pic05.jpg" alt="" /></a>
											<h3 class="major"> F : Visual odometry</h3>
											<p>
												Work on going
											</p>
											<a href="#" class="special">Learn more</a>
										</article>
										<article>
											<a href="#" class="image"><img src="images/pic05.jpg" alt="" /></a>
											<h3 class="major"> G : Global mapping & Localisation</h3>
											<p>
												Work on going
											</p>
											<a href="#" class="special">Learn more</a>
										</article>
									</section>

								</div>
							</div>

					</section>

				<!-- Footer -->
				<section id="footer">
					<div class="inner">
						<h2 class="major">Get in touch</h2>
						<p>I always believe in a collective interest over our self interest. I am open for collaborations in meaningful ventures. Open to new ideas. And hopefully I can fund young enthusiasts if you reach me. Sorry if I can't help you with big financial support. but always happy to help however I can.</p>
						<form method="post" action="#">
							<div class="fields">
								<div class="field">
									<label for="name">Name</label>
									<input type="text" name="name" id="name" />
								</div>
								<div class="field">
									<label for="email">Email</label>
									<input type="email" name="email" id="email" />
								</div>
								<div class="field">
									<label for="message">Message</label>
									<textarea name="message" id="message" rows="4"></textarea>
								</div>
							</div>
							<ul class="actions">
								<li><input type="submit" value="Send Message" /></li>
							</ul>
						</form>
						<ul class="contact">
							<li class="icon solid fa-home">
								Akhalia<br />
								Sylhet #3110<br />
								Bangladesh
								<!-- TN 00000-0000 -->
							</li>
							<li class="icon solid fa-phone">(+880) 1915640384</li>
							<li class="icon solid fa-envelope"><a href="https://mail.google.com/mail/u/0/#inbox">addeenmahbub@gmail.com</a></li>
							<!-- <li class="icon brands fa-twitter"><a href="#">twitter.com/untitled-tld</a></li> -->
							<li class="icon brands fa-facebook-f"><a href="https://www.facebook.com/sigmahermit/">/www.facebook.com/ad-deen/</a></li>
							<li class="icon brands fa-linkedin"><a href="https://www.linkedin.com/in/ad-deen-mahbub-2bb6211a0/">/linkedin.com/ad-deen/</a></li>
						</ul>
						<ul class="copyright">
							<li>&copy; Untitled Inc. All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
						</ul>
					</div>
				</section>

		</div>

	<!-- Scripts -->
		<script src="assets/js/jquery.min.js"></script>
		<script src="assets/js/jquery.scrollex.min.js"></script>
		<script src="assets/js/browser.min.js"></script>
		<script src="assets/js/breakpoints.min.js"></script>
		<script src="assets/js/util.js"></script>
		<script src="assets/js/main.js"></script>